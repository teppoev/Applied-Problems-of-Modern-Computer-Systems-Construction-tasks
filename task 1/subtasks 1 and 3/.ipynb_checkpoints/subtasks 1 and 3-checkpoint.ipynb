{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0158e27",
   "metadata": {},
   "source": [
    "Задание:\n",
    "\n",
    "1. Реализовать детектор лиц на основе метода Template Matching.\n",
    "2. Рассмотреть варианты детектора с различными шаблонами (целое лицо или его\n",
    "фрагменты).\n",
    "3. Исследовать качество детектирования лиц в различных условиях (освещение, его\n",
    "неравномерность, повороты/наклон лица, сокрытие различных частей лица\n",
    "(**использование маски и деиндентификация**), расстояние от камеры и т.д.).\n",
    "4. Сделать заключение и оценить работу собственного детектора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770737a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aa2038",
   "metadata": {},
   "source": [
    "Перебор всевозможных размеров шаблона; размер лица на входном изображении может быть любым.\\\n",
    "В качестве шаблона используется ТОЛЬКО целое лицо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f64be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recogn1(img, templates, method):\n",
    "    scale_step = 0.1\n",
    "    scale = 0.1\n",
    "    max_width = img.shape[1]\n",
    "    max_height = img.shape[0]\n",
    "    found = None\n",
    "    while True:\n",
    "        width = int(templates[0].shape[1] * scale)\n",
    "        height = int(templates[0].shape[0] * scale)\n",
    "        if width > max_width or height > max_height:\n",
    "            break\n",
    "        dim = (width, height)\n",
    "        for i in range(len(templates)):\n",
    "            template2 = cv.resize(templates[i], dim, interpolation = cv.INTER_AREA)\n",
    "            res = cv.matchTemplate(img,template2,eval(method))\n",
    "            min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "            if method in ['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']:\n",
    "                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                if found is None or min_val / width / height < found[0]: #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                    found = (min_val / width / height, min_loc, width, height) #!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "            else:\n",
    "                if found is None or max_val > found[0]:\n",
    "                    found = (max_val, max_loc, width, height)\n",
    "        \n",
    "        scale += scale_step\n",
    "    return (found[1], (found[1][0] + found[2], found[1][1] + found[3])) if not found is None else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec05674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_line1(img, image_name, methods, templates, template_name, face_recogn, idx):\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "    plt.subplot(1, len(methods) + 2, 1), plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Input Image'), plt.axis(\"off\")\n",
    "    if not idx is None:\n",
    "        plt.subplot(1, len(methods) + 2, 2), plt.imshow(templates[idx],cmap = 'gray')\n",
    "        plt.title('Template'), plt.axis(\"off\")\n",
    "    for j in range(len(methods)):\n",
    "        top_left, bottom_right = face_recogn(img, templates if idx is None else [templates[idx]], methods[j])\n",
    "        cropped_img = img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "        plt.subplot(1, len(methods) + 2, j + 3),plt.imshow(cropped_img,cmap = 'gray')\n",
    "        plt.title(methods[j]), plt.axis(\"off\")\n",
    "    plt.suptitle(f\"Image: {image_name}, Template: {template_name}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72af358",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templates_folder_name = 'templates'\n",
    "images_folder_name = 'images'\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "template_names = ['1_1.png', '2_1.png', '3_1.png', '4_1.png']\n",
    "\n",
    "templates = []\n",
    "for template_name in template_names:\n",
    "    templates.append(cv.imread(f'{templates_folder_name}/{template_name}',0))\n",
    "\n",
    "max_available_width = 1024\n",
    "\n",
    "for image_name in os.listdir(images_folder_name):\n",
    "    img = cv.imread(f'{images_folder_name}/{image_name}',0)\n",
    "    if img.shape[1] > max_available_width:\n",
    "        new_width = max_available_width\n",
    "        new_height = int(img.shape[0] * max_available_width / img.shape[1])\n",
    "        img = cv.resize(img, (new_width, new_height), interpolation = cv.INTER_AREA)\n",
    "    \n",
    "    for i in range(len(templates)):\n",
    "        display_line1(img, image_name, methods, templates, template_names[i], face_recogn1, i)\n",
    "    display_line1(img, image_name, methods, templates, \"the best\", face_recogn1, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29e6d1",
   "metadata": {},
   "source": [
    "Фиксированный размер шаблона. Фотографии вручную предобработаны, чтобы размер шаблона *примерно* соответствовал размеру лица на фотографии.\\\n",
    "Шаблоны частей лица не используются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f08aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recogn2(img, templates, method):\n",
    "    found = None\n",
    "    for i in range(len(templates)):\n",
    "        res = cv.matchTemplate(img,templates[i],eval(method))\n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "        if method in ['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']:\n",
    "            if found is None or min_val < found[0]:\n",
    "                found = (min_val, min_loc)\n",
    "        else:\n",
    "            if found is None or max_val > found[0]:\n",
    "                found = (max_val, max_loc)\n",
    "    return (found[1], (found[1][0] + templates[0].shape[1], found[1][1] + templates[0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d943599d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templates_folder_name = 'templates'\n",
    "images_folder_name = 'images'\n",
    "methods = ['cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED', 'cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED']\n",
    "template_names = ['1_1.png', '2_1.png', '3_1.png', '4_1.png']\n",
    "\n",
    "templates = []\n",
    "for template_name in template_names:\n",
    "    templates.append(cv.imread(f'{templates_folder_name}/{template_name}',0))\n",
    "\n",
    "for image_name in os.listdir(images_folder_name):\n",
    "    img = cv.imread(f'{images_folder_name}/{image_name}',0)\n",
    "    for i in range(len(templates)):\n",
    "        display_line1(img, image_name, methods, templates, template_name, face_recogn2, i)\n",
    "    display_line1(img, image_name, methods, templates, \"the best\", face_recogn2, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6816e",
   "metadata": {},
   "source": [
    "Фиксированный размер шаблона. Фотографии вручную предобработаны, чтобы размер шаблона примерно соответствовал размеру лица на фотографии.\\\n",
    "Для корректировки результата используются шаблоны частей лица."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16407d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recogn3(img, templates):\n",
    "    method = cv.TM_SQDIFF_NORMED\n",
    "    found = None\n",
    "    for i in range(len(templates)):\n",
    "        face_template = templates[i][0]\n",
    "        part_templates = templates[i][1]\n",
    "        locations = templates[i][2]\n",
    "        res = cv.matchTemplate(img, face_template, method)\n",
    "        templates_res = []\n",
    "        for template in part_templates:\n",
    "            templates_res.append(cv.matchTemplate(img, template, method))\n",
    "        suc = np.ones(res.shape)\n",
    "\n",
    "        start_min_val, start_max_val, _, _ = cv.minMaxLoc(res)\n",
    "\n",
    "        for counter in trange(max_count):\n",
    "            min_val, max_val, min_loc, _ = cv.minMaxLoc(res)\n",
    "            if (max_val - min_val < 1e-6 or\n",
    "                (min_val - start_min_val) > treshold * (start_max_val - start_min_val)):\n",
    "                break\n",
    "            top_left = min_loc\n",
    "            bottom_right = (top_left[0] + face_template.shape[1], top_left[1] + face_template.shape[0])\n",
    "            cropped_img = img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "            sum_dist = 0.0\n",
    "            for i in range(len(part_templates)):\n",
    "                min_val2, max_val2, _, _ = cv.minMaxLoc(templates_res[i])\n",
    "                loc = tuple([sum(x) for x in zip(top_left[::-1],locations[i])])\n",
    "                sum_dist += (templates_res[i][loc] - min_val2) / (max_val2 - min_val2)\n",
    "            center = min_loc[::-1]\n",
    "            suc[center] = sum_dist + counter * mult\n",
    "            for i in range(center[0] - del_range, center[0] + del_range + 1):\n",
    "                for j in range(center[1] - del_range, center[1] + del_range + 1):\n",
    "                    if i >= 0 and i < res.shape[0] and j >= 0 and j < res.shape[1]:\n",
    "                        res[(i,j)] = max_val\n",
    "        \n",
    "        min_val, _, min_loc, _ = cv.minMaxLoc(suc)\n",
    "        return (min_loc, (min_loc[0] + face_template.shape[1], min_loc[1] + face_template.shape[0]), res, min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ac128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "templates_folder_name = 'templates'\n",
    "images_folder_name = 'images'\n",
    "method = \"cv.TM_SQDIFF_NORMED\"\n",
    "face_template_name = '3_1.png'\n",
    "template_names = ['3_2.png', '3_3.jpg', '3_4.jpg', '3_5.jpg', '3_6.jpg', '3_7.jpg', '3_8.jpg']\n",
    "\n",
    "face_template = cv.imread(f'{templates_folder_name}/{face_template_name}',0)\n",
    "templates = []\n",
    "for template_name in template_names:\n",
    "    templates.append(cv.imread(f'{templates_folder_name}/{template_name}',0))\n",
    "\n",
    "locations = []\n",
    "for i in range(len(templates)):\n",
    "    template = templates[i] \n",
    "    res = cv.matchTemplate(face_template,template,eval(method))\n",
    "    min_val, _, min_loc, _ = cv.minMaxLoc(res)\n",
    "    locations.append(min_loc[::-1])\n",
    "\n",
    "treshold = 0.1\n",
    "del_range = 5\n",
    "mult = 0\n",
    "max_count = int(7.0 / mult) if abs(mult) > 1e-6 else 2000\n",
    "    \n",
    "for image_name in os.listdir(images_folder_name):\n",
    "    img = cv.imread(f'{images_folder_name}/{image_name}',0)\n",
    "    \n",
    "    top_left, bottom_right = face_recogn2(img, [face_template], method)\n",
    "    cropped_img2 = img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "    \n",
    "    top_left, bottom_right, res_matrix, dist = face_recogn3(img, [(face_template, templates, locations)])\n",
    "    cropped_img3 = img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "    plt.subplot(1, 5, 1), plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Input Image'), plt.axis(\"off\")\n",
    "    plt.subplot(1, 5, 2), plt.imshow(res_matrix,cmap = 'gray')\n",
    "    plt.title('Result Matrix'), plt.axis(\"off\")\n",
    "    plt.subplot(1, 5, 3), plt.imshow(face_template,cmap = 'gray')\n",
    "    plt.title('Template'), plt.axis(\"off\")\n",
    "    plt.subplot(1, 5, 4), plt.imshow(cropped_img2,cmap = 'gray')\n",
    "    plt.title('Old Res'), plt.axis(\"off\")\n",
    "    plt.subplot(1, 5, 5), plt.imshow(cropped_img3,cmap = 'gray')\n",
    "    plt.title('Res'), plt.axis(\"off\")\n",
    "    plt.suptitle(f\"Image name: {image_name}; distance: {dist}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aa6d5f",
   "metadata": {},
   "source": [
    "Задание\n",
    "\n",
    "1. Провести те же исследования для детектора Виола-Джонса (есть в OpenCV и MATLAB).\n",
    "2. Сделать выводы по проделанной работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f2768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_folder_name = 'images'\n",
    "templates_folder_name = 'templates'\n",
    "method1 = \"cv.TM_CCOEFF\"\n",
    "template_name1 = '1_1.png'\n",
    "method2 = \"cv.TM_SQDIFF_NORMED\"\n",
    "template_name2 = '3_1.png'\n",
    "\n",
    "template = cv.imread(f'{templates_folder_name}/{template_name}', 0)\n",
    "\n",
    "face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "for image_name in os.listdir(images_folder_name):\n",
    "    img = cv.imread(f'{images_folder_name}/{image_name}')\n",
    "\n",
    "    detected_faces = face_cascade.detectMultiScale(img)\n",
    "    res4 = img\n",
    "    \n",
    "    max_idx = -1\n",
    "    max_area = 0\n",
    "    for i in range(len(detected_faces)):\n",
    "        _, _, width, height = detected_faces[i]\n",
    "        if width * height > max_area:\n",
    "            max_area = width * height\n",
    "            max_idx = i\n",
    "    \n",
    "    gray_img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    top_left, bottom_right = face_recogn1(gray_img, [template], method)\n",
    "    res1 = img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "    \n",
    "    top_left, bottom_right = face_recogn2(gray_img, [template], method)\n",
    "    res2 = img[top_left[1]:bottom_right[1], top_left[0]:bottom_right[0]]\n",
    "    \n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (20,4)\n",
    "    plt.rcParams['figure.constrained_layout.use'] = True\n",
    "    plt.subplot(1, 4, 1), plt.imshow(cv.cvtColor(img, cv.COLOR_BGR2RGB))\n",
    "    plt.title('Input Image'), plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 2), plt.imshow(cv.cvtColor(res1, cv.COLOR_BGR2RGB))\n",
    "    plt.title('My detector; scaling: on'), plt.axis(\"off\")\n",
    "    plt.subplot(1, 4, 3), plt.imshow(cv.cvtColor(res2, cv.COLOR_BGR2RGB))\n",
    "    plt.title('My detector; scaling: off'), plt.axis(\"off\")\n",
    "    \n",
    "    plt.subplot(1, 4, 4), plt.title('Viola-Jones'), plt.axis(\"off\")\n",
    "    if max_idx >= 0:\n",
    "        column, row, width, height = detected_faces[max_idx]\n",
    "        res4 = img[row:row+height, column:column+width]\n",
    "        plt.imshow(cv.cvtColor(res4, cv.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        x = np.linspace(0, 5, 1000)\n",
    "        plt.plot(x, x, color='r')\n",
    "        ax = plt.gca()\n",
    "        circle = plt.Circle((2.5, 2.5), 2.5, color='r', fill=False)\n",
    "        ax.add_patch(circle)\n",
    "    \n",
    "    plt.suptitle(f\"{image_name}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
